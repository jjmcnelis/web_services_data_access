{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-M5_FCS_ZS0"
   },
   "source": [
    "# Accessing Data through ORNL DAAC Web Services\n",
    "## Exploring Forest Disturbance Caused by Bark Beetles at Fairview Curve, Rocky Mountain National Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vYq8f_eFsOb"
   },
   "source": [
    "*Author: ORNL DAAC*  \n",
    "*Date: April 21, 2019*  \n",
    "*Contact for ORNL DAAC: uso@daac.ornl.gov*  \n",
    "\n",
    "**Keywords:** Web service, Python, Open Geospatial Consortium (OGC), REST API, MODIS, Daymet, Spatial Data Access Tool (SDAT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNAWghRR_koy"
   },
   "source": [
    "## Web Services at the ORNL DAAC \n",
    "The [ORNL DAAC](https://daac.ornl.gov/) (Oak Ridge National Laboratory Distributed Active Archive Center) for Biogeochemical Dynamics is a National Aeronautics and Space Administration (NASA) Earth Observing System Data and Information System (EOSDIS) data center managed by the Earth Science Data and Information System  (ESDIS) Project.\n",
    "\n",
    "The ORNL DAAC offers many [tools and services](https://daac.ornl.gov/tools/) for visualization and access to data, which will be demonstrated in this tutorial.\n",
    "\n",
    "The Web services used in this tutorial include:\n",
    "* [MODIS Web Service](https://modis.ornl.gov/data/modis_webservice.html), a [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) Web service, to access [MODIS Land Products](https://modis.ornl.gov/documentation.html)\n",
    "* [Daymet Single Pixel Tool](https://daymet.ornl.gov/web_services.html), a [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) web service to access daily weather parameters offered in the [Daymet data product](https://daymet.ornl.gov/) at a single geographic point\n",
    "* [Spatial Data Access Tools (SDAT)](https://webmap.ornl.gov/ogc) offers [OGC](http://www.opengeospatial.org/)-based [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) Web services to visualize and download spatial data in various user-selected spatial/temporal extents and formats. The SDAT is a general-purpose Web application. It contains 187 archived data products (as of April 2019) in many science disciplines, including agriculture, biosphere, climate, land surface, etc.\n",
    "\t* [Web Map Service (WMS)](https://en.wikipedia.org/wiki/Web_Map_Service): Get maps (i.e., visualization) of geospatial data from a remote server\n",
    "\t* [Web Coverage Service (WCS)](https://en.wikipedia.org/wiki/Web_Coverage_Service): Download geospatial data from a remote server\n",
    "\n",
    "With both OGC WMS and WCS, you can customize maps for the data you need. For example, you can choose the spatial region, the data and map format (e.g., GeoTIFF for WCS; PNG for WMS), the coordinate reference system or projection, and the resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqJM86mfFjq8"
   },
   "source": [
    "## Overview\n",
    "In this tutorial, we will use several Web services to access and combine datasets near Fairview Curve at Rocky Mountain National Park in Colorado (latitude = 40.399391, longitude = -105.835901) to investigate tree mortality owing to bark beetle infestation from 2006-2010.\n",
    "\n",
    "![Image_Bark_Beetle_Farview_Curve](https://www.nps.gov/romo/learn/nature/images/ForestHealth_MPB_Comparison_688x300.jpg)\n",
    "\n",
    "\n",
    "The photos above were taken in late summer in 2005 (left) and 2009 (right), and illustrate the effects of bark beetle infestation. One way to quantitatively access the impacts of bark beetles on tree mortality is to use a vegetation index, which indicated the health of vegetation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4BlYkYEGBWs"
   },
   "source": [
    "### Data Products\n",
    "Data products used in theis tutorial include:\n",
    "* [MOD13Q1](https://lpdaac.usgs.gov/products/mod13q1v006/): MODIS (Collection 6) 16 day Enhanced Vegetation Index (EVI) at 250 m spatial resolution.\n",
    "\t* Accessed through MODIS Web service\n",
    "* [Daymet](https://daymet.ornl.gov/overview): Daily total precipitation and daily maximum/minimum temperature at 1 km spatial resolution.\n",
    "\t* Accessed through Daymet single pixel Web service\n",
    "* [Tree Mortality from Bark Beetles](https://doi.org/10.3334/ORNLDAAC/1512): yearly total tree motality (in Mg C km2) at 1 km Resolution in the western USA for 2003-2012\n",
    "\t* Accessed through SDAT OGC WMS and WCS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvzrUCiOGIK9"
   },
   "source": [
    "### Prerequisites\n",
    "Python 2.7 or later and modules: numpy, pandas, matplotlib, urllib, zeep, owslib, datetime, modisViirsClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bz4LraMfG-iu"
   },
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFy2Cw-e6QZ7"
   },
   "source": [
    "If a module is not installed in your Google Colab workspace, first install it via pip as `!pip install -q <module-name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjYu0jAN0ns1"
   },
   "outputs": [],
   "source": [
    "!pip install -q owslib\n",
    "!pip install -q pycurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDvDYOmvQL_W"
   },
   "source": [
    "We will use [modisViirsClient](https://github.com/tquaife/modisViirsClient)  to call ORNL DAAC's MODIS REST service. Clone the repository if it is not loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHBwDMfpQN2A"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/tquaife/modisViirsClient.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgmV7y7G6pJO"
   },
   "source": [
    "Let's import some python modules to be used in this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0GyPbzTApM6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# above generates plots in line within this page\n",
    "\n",
    "import numpy as np # numpy module for array operations\n",
    "import pandas as pd # pandas module for tabular data\n",
    "import matplotlib.pyplot as plt # matplotlib module for plotting\n",
    "import datetime as dt # datetime module for converting dates\n",
    "import json  # json lets you produce REST output in readable format\n",
    "import urllib # urllib allows you to access legend images from SDAT\n",
    "from owslib.wms import WebMapService # OWSlib module to access WMS services from SDAT\n",
    "from owslib.wcs import WebCoverageService  # OWSlib module to access WCS services from SDAT\n",
    "from IPython.display import Image # Displaying image\n",
    "\n",
    "# import modisViirsClient\n",
    "import sys\n",
    "sys.path.insert(0, 'modisViirsClient')\n",
    "from modisViirsClient import *\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTIy3LeQ6y4_"
   },
   "source": [
    "Then define the location of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5m8qIc264Ek"
   },
   "outputs": [],
   "source": [
    "# Fairview Curve, Rocky Mountain National Park, Colorado\n",
    "latitude = 40.399391\n",
    "longitude = -105.835901\n",
    "\n",
    "# Deep Creek Ridge in Central Idaho \n",
    "# latitude = 45.0949 \n",
    "# longitude = -114.1086\n",
    "\n",
    "print('Latitude: ' + str(latitude))\n",
    "print('Longitude: ' + str(longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VP3SUiLV8Ugj"
   },
   "source": [
    "### 1. Download Weather Data using the Daymet Single Pixel Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Np6Ua_ycCWoI"
   },
   "source": [
    "The Daymet Single Pixel Tool requires a url to be formated like: \n",
    "> https://<i></i>daymet.ornl.gov/data/send/saveData?lat=**lat**&lon=**lon**&measuredParams=**params**&year=**years**\n",
    "\n",
    "where **lat** and **lon** are the latitude and longitude values in decimal degrees, **params** is a comma-separated list of parameters (tmax, tmin, dayl, prcp, srad, swe, vp) and **years** is a comma-separated list of years.\n",
    "\n",
    "Here, we will download daily precipitation data (**prcp**), daily minimum temperature data (**tmin**), and daily maximum temperature data (**tmax**) from 2003-2011 at our location of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJxKZFRoBizJ"
   },
   "outputs": [],
   "source": [
    "# list of years to retrieve data\n",
    "yrs = \"2003,2004,2005,2006,2007,2008,2009,2010,2011\"\n",
    "\n",
    "# Daymet URL. It is important that the URL is structured correctly\n",
    "daymeturl = \"https://daymet.ornl.gov/data/send/saveData?lat={lat}&lon={lon}&measuredParams=prcp,tmax,tmin&year={year}\"\n",
    "\n",
    "# read daymet_file, first 6 lines are headers\n",
    "daymetdf = pd.read_csv(daymeturl.format(lat=latitude, lon=longitude, year=yrs), header=6)\n",
    "\n",
    "# convert year and day of year into python datetime\n",
    "daymetdf.index = pd.to_datetime(daymetdf.year.astype(int).astype(str) + '-' + daymetdf.yday.astype(int).astype(str), format=\"%Y-%j\")\n",
    "\n",
    "# preview the first five rows\n",
    "print('Firt 5 rows of daymetdf:')\n",
    "print(daymetdf[:5])\n",
    "\n",
    "# retrieve Daymet data in 1981-2010 to calculate 30-yr normal\n",
    "yrs = \"1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010\"\n",
    "daymetdf_30yrs = pd.read_csv(daymeturl.format(lat=latitude, lon=longitude, year=yrs), header=6)\n",
    "daymetdf_30yrs.index = pd.to_datetime(daymetdf_30yrs.year.astype(int).astype(str) + '-' + daymetdf_30yrs.yday.astype(int).astype(str), format=\"%Y-%j\")\n",
    "\n",
    "# preview the first five rows\n",
    "print('\\nFirt 5 rows of daymetdf_30yrs:')\n",
    "print(daymetdf_30yrs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAS9QXu8Ee3r"
   },
   "source": [
    "Now, rename the columns into something shorter, create annual precipitation, and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vNbJZCIChiA"
   },
   "outputs": [],
   "source": [
    "# rename columns to make them shorter and no whitespace\n",
    "daymetdf=daymetdf.rename(columns = {'prcp (mm/day)':'prcp', 'tmax (deg c)':'tmax', 'tmin (deg c)':'tmin'})\n",
    "daymetdf_30yrs=daymetdf_30yrs.rename(columns = {'prcp (mm/day)':'prcp', 'tmax (deg c)':'tmax', 'tmin (deg c)':'tmin'})\n",
    "\n",
    "# compute annual total precipitation\n",
    "daymetdf_ann = daymetdf.groupby(pd.Grouper(freq='1Y')).aggregate(np.sum)\n",
    "daymetdf_30yrs_ann = daymetdf_30yrs.groupby(pd.Grouper(freq='1Y')).aggregate(np.sum)\n",
    "\n",
    "# compute monthly mean temperature in winter season (Dec, Jan, and Feb)\n",
    "daymetdf_mon = daymetdf.groupby(pd.Grouper(freq='1M')).aggregate(np.mean)\n",
    "daymetdf_wtr = daymetdf_mon[(daymetdf_mon['yday']<59) | (daymetdf_mon['yday']>334)]\n",
    "daymetdf_wtr = daymetdf_wtr.groupby(pd.Grouper(freq='1Y')).aggregate(np.mean)\n",
    "\n",
    "daymetdf_30yrs_mon = daymetdf_30yrs.groupby(pd.Grouper(freq='1M')).aggregate(np.mean)\n",
    "daymetdf_30yrs_wtr = daymetdf_30yrs_mon[(daymetdf_30yrs_mon['yday']<59) | (daymetdf_30yrs_mon['yday']>334)]\n",
    "daymetdf_30yrs_wtr = daymetdf_30yrs_wtr.groupby(pd.Grouper(freq='1Y')).aggregate(np.mean)\n",
    "\n",
    "# make two plots\n",
    "# 1st plot shows time series of annual total precip in 2003-2011, comparing with 30-yr normal\n",
    "# 2nd plot shows time series of winter mean daily max/min temperature in 2003-2011, comparing with 30-yr winter normal\n",
    "fig = plt.figure(figsize=(14,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "daymetdf_ann.prcp.plot(legend=True, marker='o', style='b', ax=ax1)\n",
    "ax1.axhline(y=daymetdf_ann.prcp.mean(), color='r', linestyle=':')\n",
    "ax1.set(title='annual total precip in 2003-2011')\n",
    "ax1.set(ylabel='Precipitation (mm)')\n",
    "\n",
    "daymetdf_wtr.tmin.plot(legend=True, marker='o', style='b', ax=ax2)\n",
    "daymetdf_wtr.tmax.plot(legend=True, marker='o', style='r', ax=ax2)\n",
    "ax2.axhline(y=daymetdf_30yrs_wtr.tmin.mean(), color='r', linestyle=':')\n",
    "ax2.axhline(y=daymetdf_30yrs_wtr.tmax.mean(), color='b', linestyle=':')\n",
    "ax2.set(title='winter mean daily max/min temperature in 2003-2011')\n",
    "ax2.set(ylabel='Temperature (C)')\n",
    "\n",
    "print('Plots:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93Uh5TakE0sI"
   },
   "source": [
    "In the chart above, we can see that years 2004-2009 were dry (received less precipitation) compared with the 30-yr normal. During a drought period, the water-stressed trees are more susceptible to the bark beetles. Also, daily minimum temperature during winter time in years 2004-2009 was higher than normal (calculated from 1981-2010 Daymet data). Warmer winters favor the growth of bark beetle infestations.\n",
    "\n",
    "### 2. Download Vegetation Index with the MODIS Web Service\n",
    "\n",
    "Now, we will use ORNL DAAC's MODIS Web service to download the MODIS Vegetation Index (EVI from [MOD13Q1](https://doi.org/10.5067/modis/mod13q1.006)). The MODIS product MOD13Q1 is a gridded product with a time frequency of 16 days and a spatial resolution of 250 m.\n",
    "\n",
    "We will use  [modisViirsClient](https://github.com/tquaife/modisViirsClient) to access the MODIS Web service, and then print the bands available for product MOD13Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOO5booqR4Mo"
   },
   "outputs": [],
   "source": [
    "product = 'MOD13Q1' # MODIS Terra vegetation index\n",
    "\n",
    "response=modViirRequest(product)\n",
    "m=parseModViirJSON(response)\n",
    "print (json.dumps(m.bands, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1eQVdPGVQtB"
   },
   "source": [
    "The vegetation index we are interested is '250m_16_days_EVI' which contains metadata elements (e.g., scale_factor). Let's retrieve the `scale_factor` value and assign it to variable \"scale.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Waxu2NmXMaOT"
   },
   "outputs": [],
   "source": [
    "band = '250m_16_days_EVI' # EVI band\n",
    "\n",
    "evi_band = [item for item in m.bands if item['band'] == band]\n",
    "scale = float(evi_band[0]['scale_factor'])\n",
    "print(\"Scale factor: \" + str(scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-C1iTlcsgBc"
   },
   "source": [
    "Also note the '250m_16_days_VI_Quality' band which contains quality information about the band. For the sake of simplicity, we will not apply quality filters in this tutorial. Read more about the quality band [here](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf). \n",
    "\n",
    "We will now download MODIS EVI data from the start of 2003 to the end of 2012. This might take a while to run, so sit back and relax while it finishes downloading the data. Once we download the data, we apply the scale factor and arrange data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqBVDhLmVRGg"
   },
   "outputs": [],
   "source": [
    "#start and end times\n",
    "startdate=dt.datetime(year=2003,month=1,day=1)\n",
    "enddate=dt.datetime(year=2012,month=12,day=31)\n",
    "\n",
    "# count how long it takes to download all data\n",
    "print('Start: ' + str(dt.datetime.now()))\n",
    "\n",
    "# download and parse data\n",
    "response=modViirRequest(product,band=band,latitude=latitude,longitude=longitude,start_date=startdate, end_date=enddate)\n",
    "modEvi=parseModViirJSON(response)\n",
    "\n",
    "# apply scale factor and put data into a Pandas dataframe\n",
    "evidf = pd.DataFrame(data=scale*modEvi.data[band][:,0,0], index=modEvi.dates, columns=['evi'])\n",
    "\n",
    "print('End: ' + str(dt.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vo8ym6hS4cq"
   },
   "source": [
    "Save the Pandas dataframe as a CSV file so that we don't have to download the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soXACDw2Najy"
   },
   "outputs": [],
   "source": [
    "evifile = 'sample_data/modis_evi_fairview_curve.csv'\n",
    "evidf.to_csv(evifile, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TR59EDlBzIFb"
   },
   "source": [
    "To save time in this demo, instead of dynamically retrieving data from MODIS Web service, simply load data from the saved CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFt743oizdDg"
   },
   "outputs": [],
   "source": [
    "evidf = pd.read_csv('https://www.dropbox.com/s/1whpd0qg1yptqix/modis_evi_fairview_curve.csv?dl=1', index_col=0, parse_dates=True)\n",
    "evidf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gI7fGSOTRrG"
   },
   "source": [
    "Let's compute and plot the annual mean EVI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xf_ohEO0TFjT"
   },
   "outputs": [],
   "source": [
    "eviyr = evidf.groupby(pd.Grouper(freq='1Y')).aggregate(np.mean)\n",
    "\n",
    "# plot\n",
    "ax = eviyr.plot(marker='o')\n",
    "ax.set(ylabel='EVI')\n",
    "ax.set(title='Annual Mean EVI (2003-2012)')\n",
    "\n",
    "print('Plot: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Yyg1DzbaALa"
   },
   "source": [
    "The trend of the annual mean EVI values decreased significantly from 2007 to 2011 owing to tree mortality caused by bark beetles. The recovery started in 2012.\n",
    "\n",
    "### 3. Download Tree Mortality from Bark Beetles with SDAT Web Service\n",
    "\n",
    "We will use the [Tree Mortality from Fires and Bark Beetles at 1-km Resolution, Western USA, 2003-2012](https://doi.org/10.3334/ORNLDAAC/1512) dataset. This dataset provides annual estimates of tree mortality (as amount of aboveground carbon in the trees killed) due to fires and bark beetles from 2003 to 2012 on forestland in the continental western United States. The data is also available via [SDAT](https://webmap.ornl.gov/ogc/dataset.jsp?ds_id=1512.). \n",
    "\n",
    "If you look up the URLs of each granules, you will notice that the bark beetle data from 2003-2012 have 'dg_id' of '1512_1', '1512_3', '1512_5',...,'1512_17', '1512_19'. These are the layer names we will need when accessing the SDAT service.\n",
    "\n",
    "Let's first connect to the ORNL DAAC WMS and retrieve its Capabilities document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lbl42yvETcPL"
   },
   "outputs": [],
   "source": [
    "sdatwms = WebMapService('https://webmap.ornl.gov/ogcbroker/wms')\n",
    "print(str(len(sdatwms.contents)) + ' layers found from ' + sdatwms.identification.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrruWjsJC980"
   },
   "source": [
    "List WMS layers that belong to dataset number 1512: Tree Mortality from Fires and Bark Beetles at 1-km Resolution, Western USA, 2003-2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnAClc5I1IWY"
   },
   "outputs": [],
   "source": [
    "# define a filter function to find layers whose name start with '1512_'\n",
    "def myFilter(x):\n",
    "  if x.startswith('1512_'):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "# filter layers\n",
    "myLayers = filter(myFilter, sdatwms.contents)\n",
    "for l in myLayers:\n",
    "  print(sdatwms[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "capJY1rgDyOn"
   },
   "source": [
    "Print out some metadata associated with layer 1512_1: Tree Mortality from Bark Beetles in the Western USA 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecuwwIKeD4Ma"
   },
   "outputs": [],
   "source": [
    "print('Layer:')\n",
    "print(sdatwms['1512_1'].title)\n",
    "print('Bounding Box:')\n",
    "print(sdatwms['1512_1'].boundingBox)\n",
    "print('Bounding Box (WGS84):')\n",
    "print(sdatwms['1512_1'].boundingBoxWGS84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ektG_GHaaMNW"
   },
   "source": [
    "Then check what methods and format options are available for the WMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "285cNKgXaGAT"
   },
   "outputs": [],
   "source": [
    "[op.name for op in sdatwms.operations]\n",
    "sdatwms.getOperationByName('GetMap').formatOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIUh5vgkaURz"
   },
   "source": [
    "We will use the WMS \"GetMap\" operation to download the images in PNG format for years 2003-2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBq-X2_paSAC"
   },
   "outputs": [],
   "source": [
    "# specify x/y spatial resolution in decimal degrees\n",
    "resx = 0.010 \n",
    "resy = 0.010\n",
    "\n",
    "# The date range is 2003-2011\n",
    "mortDates = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011] \n",
    "\n",
    "# odd numbered array starting from 1 to 17\n",
    "odd_i = range(1, 18, 2)\n",
    "for i, j in enumerate(odd_i):\n",
    "    layername = '1512_' + str(j)\n",
    "    img = sdatwms.getmap(layers=[layername],\n",
    "                     srs='EPSG:4326', # WGS 84\n",
    "                     bbox=(longitude-resx,latitude-resy,longitude+resx,latitude+resy), \n",
    "                     size=(100, 100), \n",
    "                     format='image/png', \n",
    "                     transparent=True)\n",
    "    print(mortDates[i])\n",
    "    display(Image(img.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jUUPYjsaac_"
   },
   "source": [
    "In the above images, higher tree mortality is displayed in darker red and no mortality in green. Mortality peaked between 2008 and 2009.\n",
    "\n",
    "We need a legend for the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCvh1dTBD047"
   },
   "outputs": [],
   "source": [
    "legend_url = sdatwms['1512_1'].styles['default']['legend']\n",
    "urllib.urlretrieve(legend_url, 'sample_data/avhrr_legend.png')\n",
    "display(Image('sample_data/avhrr_legend.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WhcgbHEEUah"
   },
   "source": [
    "To retrieve the tree mortality rates, we use SDAT's WCS. Then we plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynPVNxUnaXI6"
   },
   "outputs": [],
   "source": [
    "sdatwcs = WebCoverageService('https://webmap.ornl.gov/ogcbroker/wcs')\n",
    "mort = [] # array to store mortality values (Mg C km-2)\n",
    "\n",
    "for i,j in enumerate(odd_i):\n",
    "    layername = '1512_' + str(j)\n",
    "    mortality = sdatwcs.getCoverage(identifier=layername,\n",
    "                           bbox=(longitude-resx,latitude-resy,longitude+resx,latitude+resy),\n",
    "                           crs='EPSG:4326',\n",
    "                           format='XYZ_FLOAT32',\n",
    "                           interpolation='NEAREST',\n",
    "                           resx=resx,\n",
    "                           resy=resy)\n",
    "    \n",
    "    # output from above is in bytes; lets convert to string\n",
    "    mortOut = mortality.read().decode(\"utf-8\")\n",
    "    mortValue = []\n",
    "    \n",
    "    # loop through the output and store mortality values\n",
    "    for k, lines in enumerate(mortOut.splitlines()):\n",
    "        if k > 0: # skipping the header line\n",
    "            mortValue.append(int(lines.split(',')[2]))\n",
    "    \n",
    "    # mean mortality (Mg C km-2)\n",
    "    mort.append(np.mean(mortValue))\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "mortdf = pd.DataFrame(data=mort, index=mortDates, columns=['mortality'])\n",
    "\n",
    "# print the tree mortality due to bark beetle\n",
    "print(mortdf)\n",
    "\n",
    "# plot it\n",
    "mortdf.plot(marker='o')\n",
    "plt.ylabel('Tree Mortality (Mg C km-2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7gB7ooRaitk"
   },
   "source": [
    "### 4. Summary\n",
    "The bark beetle infestation is often triggered by drought, with beetle activity becoming detectable within a year or two. As soon as the tree recovers from drought, the beetle [populations collapse and tree mortality diminishes](https://www.fs.usda.gov/detail/boise/news-events/?cid=STELPRD3841444). In this tutorial, we demonstrated basic methods to access data from three different Web services hosted at the ORNL DAAC. Now, can you put together the three datasets we just downloaded (vegetation index from MODIS, precipitation from Daymet, and tree mortality from an archived dataset) and draw conclusions from them.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ornl-daac-webservices.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
